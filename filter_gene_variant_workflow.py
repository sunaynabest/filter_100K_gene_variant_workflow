# WHAT DOES THIS SCRIPT DO
# It filters a TSV output file generated by the GeneVariantWorkflow script based on specified criteria to give several shorter lists of interesting variants to analyse.
# Filtering steps include removal of common variants from gnomAD and the 100K rare disease dataset, then filtering into separate files for rare homozygous variants, rare high impact variants, rare ClinVar pathogenic variants and rare missense variants.
#GeneVariantWorkflow will have extracted all variants across the 100K rare disease dataset in a given gene and annotated them with Ensembl VEP
#
# STEPS TO USE THIS SCRIPT
# 1) Ensure you are runing python in the correct environment.
#    There should be "(idppy3)" at the start of your terminal line
#    If not:
#       1a) . /resources/conda/miniconda3/etc/profile.d/conda.sh
#       1b) conda activate idppy3
# 2) Navigate to the GeneVariantWorkflow folder containing this script (for me under /re_gecip/GW_SB/GeneVariantWorkflow)
# 3) To run on the command line enter: python filter_gene_variant_workflow.py <enter-the-path-to-your-folder-here> <enter-your-tsv-file-name-here>
# NOTE: path to your folder should be the one containing the GeneVariantWorkflow data output files: for me it's at /home/sbest1/re_gecip/shared_allGeCIPs/GW_SB/GeneVariantWorkflow/<gene_name>/v1.7/final_output/data
# Note: The tsv file must end in ".tsv". It must be tab delimited.
# Note: Output files will be placed into a new folder named after the input tsv file within the final_output/data folder that contains your input file.
#
# ERRORS:
# ERR1: You have not included the file path after running the script
# ERR2: The input file you have linked to does not end in ".tsv"
# ERR3: The input file does not exist at the path you have provided
# ERR4: The input tsv file you have provided is not in the expected format. It must be tab delineated.
# ERR5: One of the input tsv file lines has no VEP output - this should never happen.

# Imports
import pandas as pd # Used for data maniulation
import io # Used to convert the lines of the data files into python-readable data
import os # Used to manipulate file paths
import sys # Used to obtain variables from terminal function call

# Check a file has been provided as an argument
try:
    path_to_folder = sys.argv[1] # Get the file path from the terminal function call
    tsv_file_name = sys.argv[2] # Get the VCF file name from the terminal function call
except:
    raise SystemExit("ERR1: Include the path of the folder and the tsv file name when running this script.")

# Check the provided files are on the correct format
if tsv_file_name.split('.')[-1] != 'tsv':
    raise SystemExit("ERR2: The file to analyse must be in TSV format.")

# Check files specified in the terminal function exist
tsv_file_path = os.path.join(path_to_folder, tsv_file_name)
if not os.path.isfile(tsv_file_path):
    raise SystemExit("ERR3: The tsv file provided to analyse does not exist at the following path: \n" + tsv_file_path)

# Load CSV file, skipping header rows
try:
    tsv = pd.read_csv( # Read the lines into Pandas
        tsv_file_path, # Join the lines of the CSV file into data that Pandas can read
        sep='\t' # Tell pandas that our file uses Tabs to separate values
    )
except:
    raise SystemExit("ERR4: The tsv file you have provided is not in the expected format, it must be tab deliminated")

# If folder for results doesn't exist then create it
folder_name = tsv_file_name.split('.')[0]
path_to_save_folder = os.path.join(path_to_folder, folder_name)
if not os.path.exists(path_to_save_folder):
    os.mkdir(path_to_save_folder)

print(f'TSV Shape: {tsv.shape}')

print(tsv.columns.values)

# **** PREPARING COLUMN TYPES FOR FILTERING ****
tsv.MAF_variant = tsv.MAF_variant.apply(pd.to_numeric, errors='coerce') # Change all the entries in the MAX_AF column to numbers
tsv.MAF_variant.fillna(0, inplace=True) # Change empty entries to 0
tsv.gnomAD_AF_annotation = tsv.gnomAD_AF_annotation.apply(pd.to_numeric, errors='coerce') # Change all the entries in the gnomAD_AF column to numbers
tsv.gnomAD_AF_annotation.fillna(0, inplace=True) # Change empty entries to 0
tsv.AC_Hom_variant = tsv.AC_Hom_variant.apply(pd.to_numeric, errors='coerce') # Change all the entries in the AC_Hom_variant column to numbers
tsv.AC_Hom_variant.fillna(0, inplace=True) # Change empty entries to 0

# **** FILTERING ****
filtered_data_1 = tsv[tsv.MAF_variant <= 0.002] # Remove all entries with MAF_variant > 0.002. These are common variants (>0.2%) called in the 100K data set
print(f'Rare 100K dataset filter length: {filtered_data_1.shape}')
filtered_data_1.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_gel_rare.csv')) # Write the filtered file to the new folder
del tsv

# **** FILTERING ****
filtered_data_2 = filtered_data_1[filtered_data_1.gnomAD_AF_annotation <= 0.002] # Remove all entries with gnomAD_AF_annotation > 0.002. These are common variants (>0.2%) called in the gnomAD dataset.
print(f'Rare 100K and gnomAD filter length: {filtered_data_2.shape}')
filtered_data_2.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_gel_gnomAD_rare.csv')) # Write the filtered file to the folder

# **** FILTERING ****
filtered_data_3 = filtered_data_2[filtered_data_2.CANONICAL_annotation == "YES"] # Retain only variants called in the canonical transcript.
print(f'Rare canonical transcript filter length: {filtered_data_3.shape}')
filtered_data_3.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_canonical_transcript_rare.csv')) # Write the filtered file to the folder

# **** FILTERING ****
filtered_data_4 = filtered_data_3[filtered_data_3.AC_Hom_variant > 0] # Remove all entries with AC_Hom_variant = 0. This will leave variants called at least once as homozygous in the rare disease 100K dataset.
print(f'Homozygous filter length: {filtered_data_4.shape}')
filtered_data_4.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_rare_homozygous.csv')) # Write the filtered file to the folder

# **** FILTERING ****
filtered_data_5 = filtered_data_3[filtered_data_3.IMPACT_annotation == "HIGH"] # Retain all entries with "HIGH" in the Impact_annotation column. This will give a file of variants rare in 100K and gnomAD that are high impact.
print(f'High impact filter length: {filtered_data_5.shape}')
filtered_data_5.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_rare_HIGH_impact.csv')) # Write the filtered file to the folder
del filtered_data_5

filtered_data_8 = filtered_data_4[filtered_data_4.IMPACT_annotation == "HIGH"] # Retain all entries with "HIGH" amongst the homozygous variants
print(f'Homozygous high impact filter length: {filtered_data_8.shape}')
filtered_data_8.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_homozygous_rare_HIGH_impact.csv')) # Write the filtered file to the folder
del filtered_data_8

# **** FILTERING ****
filtered_data_6 = filtered_data_3[filtered_data_3.ClinVar_CLNSIG_annotation.str.contains('[Pp]athogenic$', regex=True)] # Retain all entries anonotated as pathogenic in ClinVar_CLNSIG_annotation column. This catches variants rare in 100K and gnomAD called 'pathogenic' and 'likely_pathogenic'.
print(f'Pathogenic filter length: {filtered_data_6.shape}')
filtered_data_6.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_rare_ClinVAR_pathogenic.csv')) # Write the filtered file to the folder
del filtered_data_6

# **** FILTERING ****
filtered_data_7 = filtered_data_3[filtered_data_3.Consequence_annotation.str.contains('missense')] # Retain all entries with missense in CLIN_SIG_annotation column. Gives output file of rare missenses from 100K and gnomAD. NOTE: don't have CADD scores, may need to run through VEP with plugins if want this.
print(f'Missense filter length: {filtered_data_7.shape}')
filtered_data_7.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_rare_missense_all.csv')) # Write the filtered file to the folder

filtered_data_9 = filtered_data_7[filtered_data_7.SIFT_annotation.str.contains('deleterious')] # Retain all entries with SIFT_annotation entry containing deleterious. NOTE: don't have CADD scores, may need to run through VEP with plugins if want this.
print(f'Missense SIFT deleterious filter length: {filtered_data_9.shape}')
filtered_data_9.to_csv(os.path.join(path_to_save_folder, r'gene_variant_workflow_rare_missense_SIFT_deleterious.csv')) # Write the filtered file to the folder

print("Complete!")
